{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'concatenate': 0.0022644996643066406,\n",
       " 'stack': 0.006102323532104492,\n",
       " 'vstack': 0.004021406173706055}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 生成测试数据\n",
    "n_arrays = 1000\n",
    "array_length = 1000\n",
    "\n",
    "# 创建一个包含1000个长度为1000的numpy数组的数组，dtype为float32\n",
    "data = np.array([np.random.rand(array_length).astype(np.float64) for _ in range(n_arrays)], dtype=object)\n",
    "\n",
    "# 计时函数\n",
    "def benchmark_conversion(method, data):\n",
    "    start_time = time.time()\n",
    "    result = method(data)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time\n",
    "\n",
    "# 定义各个方法\n",
    "methods = {\n",
    "    \"concatenate\": lambda x: np.concatenate(x).reshape(n_arrays, array_length),\n",
    "    \"stack\": lambda x: np.stack(x),\n",
    "    \"vstack\": lambda x: np.vstack(x)\n",
    "}\n",
    "\n",
    "# 进行benchmark\n",
    "benchmark_results = {name: benchmark_conversion(method, data) for name, method in methods.items()}\n",
    "\n",
    "# 返回耗时结果\n",
    "benchmark_times = {name: time for name, (result, time) in benchmark_results.items()}\n",
    "benchmark_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunpos_filename = 'data/TUDelft/output_20240902_125140/intermediate/sun_pos.csv'\n",
    "ground_recording_filename = 'data/TUDelft/measured_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunpos = pd.read_csv(sunpos_filename)\n",
    "sunpos.columns.values[0]='timestamp'\n",
    "ground_recording = pd.read_csv(ground_recording_filename)\n",
    "sunpos['timestamp'] = pd.to_datetime(sunpos['timestamp']).dt.tz_localize(None)\n",
    "ground_recording['local_time'] = pd.to_datetime(ground_recording['local_time'])\n",
    "filtered_ground_recording = ground_recording[ground_recording['local_time'].isin(sunpos['timestamp'])]\n",
    "filtered_sunpos = sunpos[sunpos['timestamp'].isin(ground_recording['local_time'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 转换 df2 的 local_time 为 datetime 类型\n",
    "\n",
    "\n",
    "# 过滤 df2，只保留与 df1['timestamp'] 匹配的行\n",
    "filtered_df2 = df2[df2['local_time'].isin(df1['timestamp'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunpos = pd.read_csv(sunpos_filename)\n",
    "sunpos.columns.values[0]='timestamp'\n",
    "\n",
    "irradiance_data = epw[0]\n",
    "irradiance_data.index = pd.to_datetime(irradiance_data.index)\n",
    "\n",
    "sunpos['timestamp'] = pd.to_datetime(sunpos['timestamp'], utc=True)\n",
    "all_ghi = []\n",
    "all_dni = []\n",
    "all_dhi = []\n",
    "# all_solar_zenith = []\n",
    "# all_solar_azimuth = []\n",
    "# all_dni_extra = []\n",
    "\n",
    "for index, row in sunpos.iterrows():\n",
    "        row_time = row['timestamp'].tz_convert(irradiance_data.index.tz)\n",
    "        month, day, hour = row_time.month, row_time.day, row_time.hour\n",
    "        if month == 2 and day == 29:\n",
    "            day = 28\n",
    "        match = irradiance_data[(irradiance_data.index.month == month) & \n",
    "                    (irradiance_data.index.day == day) & \n",
    "                    (irradiance_data.index.hour == hour)]\n",
    "        # solar_zenith = row['apparent_zenith']\n",
    "        # solar_azimuth = row['azimuth']\n",
    "        # dni_extra = pvlib.irradiance.get_extra_radiation(row['timestamp'])\n",
    "        if (not match.empty):\n",
    "            ghi, dni, dhi, dni_extra = match.iloc[0][['ghi', 'dni', 'dhi', 'etrn']]\n",
    "            if dni_extra == 0:\n",
    "                dni_extra = pvlib.irradiance.get_extra_radiation(row['timestamp'])\n",
    "            all_ghi.append(ghi)\n",
    "            all_dni.append(dni)\n",
    "            all_dhi.append(dhi)\n",
    "            # all_solar_zenith.append(solar_zenith)\n",
    "            # all_solar_azimuth.append(solar_azimuth)\n",
    "            # all_dni_extra.append(dni_extra)\n",
    "        else:\n",
    "            print(\"error finding match\")\n",
    "\n",
    "tud_data = np.column_stack((all_ghi, all_dhi, all_dni))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
